# Mini Data Platform

A lightweight **real-time data processing platform** built with **PostgreSQL, Debezium, Kafka, Spark Streaming, and MinIO (Delta Lake)**.\
This project was developed as the final assignment for the Introduction to Big Data course, part of my Master's degree.

## Architecture

CSV Files\
    ↓\
PostgreSQL\
    ↓ (CDC)\
Debezium\
    ↓\
Kafka\
    ↓\
Spark Streaming\
    ↓\
MinIO (Delta Lake)\


## Requirements

- Docker Desktop  
- Python 3.8+  
- PowerShell (Windows)


## Project Structure

mini-data-platform\
├── data\
│ ├── customers.csv\
│ ├── orders.csv\
│ └── products.csv\
├── debezium\
│ └── connector.json\
├── python\
│ └── csv_to_postgres.py\
├── spark\
│ └── streaming.py\
├── deploy-platform.ps1\
├── docker-compose.yml\
├── README.md\
└── requirements.txt


## Quick Start

### 1. Install Python dependencies

```bash
    pip install -r requirements.txt
```
2. Start the platform
```
    .\deploy-platform.ps1
```
The script automatically:

- Starts all Docker containers

- Waits for services to become ready

- Loads CSV data into PostgreSQL

- Configures the Debezium connector

- Starts Spark Streaming Job

Components
PostgreSQL (port 5432)

    Database: datadb

    User: datauser

    Password: datapass

    Tables: customers, orders, products

Kafka (port 9092)

    Broker: localhost:9092

    Topics (generated by Debezium):

        dbserver1.public.customers

        dbserver1.public.orders

        dbserver1.public.products

Debezium Connect (port 8083)

    API: http://localhost:8083

    Monitors PostgreSQL using Change Data Capture (CDC)

    Publishes change events to Kafka in JSON format

Spark (port 8080)

    Spark Master UI: http://localhost:8080

    Consumes data from Kafka

    Writes data to MinIO in Delta Lake format

MinIO (ports 9000, 9001)

    API: http://localhost:9000

    Console: http://localhost:9001

    Credentials: minio / minio123

    Bucket: data

    Delta tables:

        s3a://data/delta/orders/

Testing
1. Insert test data into PostgreSQL
```
docker exec -it mini-data-platform-postgres-1 psql -U datauser -d datadb

INSERT INTO orders VALUES (999, 1, 1, 5);
INSERT INTO customers VALUES (100, 'Jan Kowalski', 'jan@example.com');
```
2. Check Spark logs
```
docker logs spark -f
```
3. Verify data in MinIO
```
    Open http://localhost:9001

    Log in using minio / minio123

    Open bucket data

    Navigate to delta/orders/
```
4. Load data from the Data Lake (Delta Lake)
```
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .config("spark.jars.packages", "io.delta:delta-core_2.12:2.4.0") \
    .getOrCreate()

df = spark.read.format("delta").load("s3a://data/delta/orders")
df.show()
```
Management
- Check platform status
```
docker compose ps
```
- View service logs
```
docker logs postgres
docker logs kafka
docker logs debezium
docker logs spark
docker logs minio
```
- Check Debezium connector status
```
curl http://localhost:8083/connectors/postgres-connector/status
```
- Stop the platform and wipe the data
```
docker compose down -v --remove-orphans
```


